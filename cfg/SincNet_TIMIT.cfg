[data]
tr_lst=data_lists/TIMIT_train.scp
te_lst=data_lists/TIMIT_test.scp
lab_dict=data_lists/TIMIT_labels.npy
data_folder=NORM_TIMIT
output_folder=exp/SincNet_TIMIT/
# adding to switch training and evaluating
isTraining=True
# pt_file=exp/SincNet_TIMIT/Sinc_linearly_model_raw.pkl
# pt_file=exp/SincNet_TIMIT/Sinc_model_raw.pkl
pt_file=none


[windowing]
fs=16000
cw_len=200
cw_shift=10

[cnn]
cnn_N_filt=80,60,60
cnn_len_filt=251,5,5

cnn_max_pool_len=3,3,3
cnn_use_laynorm_inp=True
cnn_use_batchnorm_inp=False
cnn_use_laynorm=True,True,True
cnn_use_batchnorm=False,False,False
cnn_act=leaky_relu,leaky_relu,leaky_relu
cnn_drop=0.0,0.0,0.0

# to switch the first convolution (standard convolution and sinc convolution) 
use_SinConv=True
# to switch between mel scale and linearly spaced of bank filter
use_mel_scale = False
# to switch between linearly and randomly spaced of bank filter When use_mel_scale = False
use_randomly_spaced = True

[dnn]
fc_lay=2048,2048,2048
fc_drop=0.0,0.0,0.0
fc_use_laynorm_inp=True
fc_use_batchnorm_inp=False
fc_use_batchnorm=True,True,True
fc_use_laynorm=False,False,False
fc_act=leaky_relu,leaky_relu,leaky_relu

[class]
class_lay=462
class_drop=0.0
class_use_laynorm_inp=False
class_use_batchnorm_inp=False
class_use_batchnorm=False
class_use_laynorm=False
class_act=softmax

[optimization]
lr=0.001
batch_size=128
N_epochs=200
N_batches=800
N_eval_epoch=8
seed=1234
